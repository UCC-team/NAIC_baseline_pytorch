########!!!!!!!!!!!
xxxxxxxxxxxxxxxxxxx
  复赛结束后开源
xxxxxxxxxxxxxxxxxxx
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import struct\n",
    "from utils import *\n",
    "import random\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from apex import amp\n",
    "import time\n",
    "\n",
    "import scipy.special\n",
    "sigmoid = lambda x: scipy.special.expit(x)\n",
    "\n",
    "# Parameters for training\n",
    "gpu_list = '0,1,2,3,4,5,6,7'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_list\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHTONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for training\n",
    "batch_size = 512\n",
    "epochs = 200\n",
    "warmup_epoch = 2\n",
    "learning_rate = 1e-3 \n",
    "lr_div_factor = 20.0\n",
    "num_workers = 32\n",
    "val_times = 10\n",
    "\n",
    "# parameters for data\n",
    "# mode [0,1,2]\n",
    "# SNRdb (8to12)\n",
    "Pilotnum = 32 # Y1:32 Y2:8 \n",
    "NO_NOISE = False #False # SNR=100 else (8to12)  \n",
    "FIX_MODE = False # mode=MODE else random choose from [0,1,2]\n",
    "MODE = 0\n",
    "\n",
    "# param of training data and criterion setting\n",
    "RESHAPE = True # false: fc  true: conv\n",
    "# NUM_SAMPLE = 20000\n",
    "MSE_or_BCE = 0 # 0 MSE 1 BCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=open('../input/H.bin','rb')\n",
    "H1=struct.unpack('f'*2*2*2*32*320000,data_train.read(4*2*2*2*32*320000))\n",
    "H1=np.reshape(H1,[320000,2,4,32])\n",
    "H=H1[:,1,:,:]+1j*H1[:,0,:,:]\n",
    "H_train = H\n",
    "# random.shuffle(H)\n",
    "\n",
    "# H_train = H[:30000] \n",
    "# H_val = H[300000:]\n",
    "\n",
    "# H_train = H_train[:30000] # for debug\n",
    "# H_val = H_val[:2000] # for debug\n",
    "\n",
    "data_val=open('../input/H_val.bin','rb')\n",
    "H1=struct.unpack('f'*2*2*2*32*2000,data_val.read(4*2*2*2*32*2000))\n",
    "H1=np.reshape(H1,[2000,2,4,32])\n",
    "H_val=H1[:,1,:,:]+1j*H1[:,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ifft(y):#256子载波 * mimo2 * 2(导频/数据) * 2(实部/虚部)\n",
    "#     y_antenna0 = 20*y[:,0,:,:]  #256子载波 * 2(导频/数据) * 2(实部/虚部)\n",
    "#     y_antenna1 = 20*y[:,1,:,:]  #256子载波 * 2(导频/数据) * 2(实部/虚部)\n",
    "    \n",
    "#     y_pilot0 = y_antenna0[:,0,0] + y_antenna0[:,0,1]*1j\n",
    "#     y_data0 = y_antenna0[:,1,0] + y_antenna0[:,1,1]*1j\n",
    "#     y_pilot0 = np.fft.ifft(y_pilot0)\n",
    "#     y_data0 = np.fft.ifft(y_data0)\n",
    "    \n",
    "#     y_pilot1 = y_antenna1[:,0,0] + y_antenna1[:,0,1]*1j\n",
    "#     y_data1 = y_antenna1[:,1,0] + y_antenna1[:,1,1]*1j\n",
    "#     y_pilot1 = np.fft.ifft(y_pilot1)\n",
    "#     y_data1 = np.fft.ifft(y_data1)\n",
    "\n",
    "#     y[:,0,1,0] = y_data0.real\n",
    "#     y[:,0,1,1] = y_data0.imag\n",
    "#     y[:,0,0,0] = y_pilot0.real \n",
    "#     y[:,0,0,1] = y_pilot0.imag\n",
    "#     y[:,1,1,0] = y_data1.real\n",
    "#     y[:,1,1,1] = y_data1.imag\n",
    "#     y[:,1,0,0] = y_pilot1.real\n",
    "#     y[:,1,0,1] = y_pilot1.imag\n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OFDMDataset(Dataset):\n",
    "    def __init__(self, H, Pilotnum=32, train=True): # Pilotnum: 32(Y1) or 8(Y2)\n",
    "        self.H = H\n",
    "        self.Pilotnum = Pilotnum\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.H) #NUM_SAMPLE\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        binomial = torch.distributions.binomial.Binomial(total_count=1, probs=0.5*torch.ones(128*4))\n",
    "        self.bits0 = binomial.sample().numpy()\n",
    "        self.bits1 = binomial.sample().numpy()\n",
    "        X = [self.bits0, self.bits1]\n",
    "        HH = self.H[idx] #self.H[torch.randint(0,len(self.H),size=(1,))]\n",
    "        if NO_NOISE:\n",
    "            SNRdb = 100\n",
    "        elif self.train:\n",
    "            SNRdb = torch.Tensor(1,).uniform_(7.95, 12.1).numpy() # 8 to 12\n",
    "        else:\n",
    "            SNRdb = torch.Tensor(1,).uniform_(8.0,12.0).numpy() # 8 to 12\n",
    "        if not FIX_MODE:\n",
    "            mode = torch.randint(0,3,size=(1,))\n",
    "        else:\n",
    "            mode = MODE \n",
    "        YY = MIMO(X, HH, SNRdb, mode, self.Pilotnum) / 20  ###\n",
    "        XX = np.concatenate((self.bits0, self.bits1), 0)\n",
    "        if RESHAPE:\n",
    "            YY = YY.reshape(256, 2, 2, 2) # 256子载波 * mimo2 * 2(导频/数据) * 2(实部/虚部)\n",
    "            #YY = YY.transpose(2,1,3,0).reshape(2,4,256) #2(导频/数据) x 4 x 256\n",
    "        return XX, YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = OFDMDataset(H_train, Pilotnum, True)\n",
    "dataset_val = OFDMDataset(H_val, Pilotnum, False)  # *= val_times\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x *( torch.tanh(F.softplus(x)))\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.inplace:\n",
    "            x.mul_(torch.sigmoid(x))\n",
    "            return x\n",
    "        else:\n",
    "            return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConv(nn.Module):\n",
    "    def __init__(self, dim=512, k=(1,1), groups=1, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(dim, dim, k, bias=False, groups=groups),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(dim, dim, k, bias=False, groups=groups),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x + self.dense(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "multiple = 64\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_pilot = nn.Sequential(\n",
    "            nn.Conv2d(256, 1024, (2,2), bias=False),\n",
    "            ResConv(dim=1024, k=(1,1)),\n",
    "            ResConv(dim=1024, k=(1,1)),\n",
    "            nn.Conv2d(1024, 1024*multiple, (1,1), bias=True),\n",
    "        )\n",
    "        \n",
    "        self.conv_data = nn.Sequential(\n",
    "            nn.Conv2d(256, 1024*multiple, (2,2), bias=False, groups=256),\n",
    "            ResConv(dim=1024*multiple, k=(1,1), groups=256),\n",
    "            ResConv(dim=1024*multiple, k=(1,1), groups=256),\n",
    "            ResConv(dim=1024*multiple, k=(1,1), groups=256),  \n",
    "            nn.Conv2d(1024*multiple, 1024*multiple, (1,1), bias=True, groups=256),\n",
    "        )\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1024*multiple, 1024*multiple, (2,1), bias=False, groups=256),\n",
    "            ResConv(dim=1024*multiple, k=(1,1), groups=256),\n",
    "            ResConv(dim=1024*multiple, k=(1,1), groups=256), \n",
    "            ResConv(dim=1024*multiple, k=(1,1), groups=256),  \n",
    "            ResConv(dim=1024*multiple, k=(1,1), groups=256),  \n",
    "            ResConv(dim=1024*multiple, k=(1,1), groups=256),  \n",
    "            nn.Conv2d(1024*multiple, 1024, (1,1), bias=True, groups=256),\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input:               # (bs,256,2,2,2)\n",
    "        x_pilot = x[:,:,:,0,:] # (bs,256,2,2)\n",
    "        x_data = x[:,:,:,1,:]  # (bs,256,2,2)\n",
    "     \n",
    "        x_pilot = self.conv_pilot(x_pilot) # (bs,1024x,1,1)\n",
    "        x_data = self.conv_data(x_data)    # (bs,1024x,1,1)\n",
    "        \n",
    "        x = torch.cat([x_data,x_pilot], axis=2)   # (bs,1024x,2,1)\n",
    "        \n",
    "        x = self.conv(x)        # (bs,1024,1,1)\n",
    "        \n",
    "        x = torch.squeeze(x)    # (bs,1024)\n",
    "        x1 = x[:,0::2]\n",
    "        x2 = x[:,1::2]\n",
    "        x = torch.cat([x1,x2], axis=1)  # (bs,1024)\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0<=smoothing<1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0-smoothing) + 0.5*smoothing\n",
    "        return targets\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1), self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets, self.weight)\n",
    "        \n",
    "        if self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.mean()\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MSE_or_BCE:\n",
    "    criterion = nn.MSELoss()\n",
    "    criterion_test = nn.MSELoss()\n",
    "    thre = 0.5\n",
    "else:\n",
    "    criterion = SmoothBCEwLogits(smoothing=0.01) #nn.BCEWithLogitsLoss()\n",
    "    criterion_test = nn.BCEWithLogitsLoss()\n",
    "    thre = 0.0                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_scheduler import CosineAnnealingWarmUpRestarts\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate/lr_div_factor, weight_decay=2e-5)\n",
    "\n",
    "# model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n",
    "\n",
    "if len(gpu_list.split(',')) > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "T = len(train_loader) * epochs \n",
    "T_up = len(train_loader) * warmup_epoch\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=T, T_mult=2, eta_max=learning_rate, T_up=T_up, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ber = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(gpu_list.split(',')) > 1:\n",
    "#     model.module.load_state_dict(torch.load('model%d.pth'%Pilotnum))\n",
    "# else:\n",
    "#     model.load_state_dict(torch.load('model%d.pth'%Pilotnum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print('========================')\n",
    "    print('lr:%.4e'%optimizer.param_groups[0]['lr']) \n",
    "  \n",
    "    # model training\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for i, (X,Y) in enumerate(train_loader):\n",
    "        X,Y = X.float().cuda(), Y.float().cuda()\n",
    "        output = model(Y)\n",
    "        loss = criterion(output, X)\n",
    "        loss.backward()\n",
    "#         with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "#             scaled_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0, norm_type=2)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    avg_tr_loss = sum(losses)/len(losses)\n",
    "    print('Epoch: [{0}]\\t'\n",
    "          'Loss {loss:.4f}\\t'.format(\n",
    "        epoch,  loss=avg_tr_loss))\n",
    "    \n",
    "    model.eval()\n",
    "    eval_losses = []\n",
    "    ber_list = []\n",
    "    for _ in range(val_times):\n",
    "        with torch.no_grad():\n",
    "            for i, (X,Y) in enumerate(val_loader):\n",
    "                X,Y = X.float().cuda(), Y.float().cuda()\n",
    "                output = model(Y)\n",
    "                eval_losses.append(criterion_test(output, X).item())\n",
    "                ber = ((output.detach() > thre) == X.bool()).cpu().numpy().mean()  #mse: 0.5  bce: 0\n",
    "                ber_list.append(ber)\n",
    "    avg_eval_loss = sum(eval_losses)/len(eval_losses)\n",
    "    avg_eval_ber = 1 - sum(ber_list)/len(ber_list)\n",
    "    print('Val Loss: %.4f | Val BER: %.5f'%(avg_eval_loss,avg_eval_ber))\n",
    "          \n",
    "    if avg_eval_ber < best_ber:\n",
    "        \n",
    "        if len(gpu_list.split(',')) > 1:\n",
    "            torch.save(model.module.state_dict(), 'model%d.pth'%Pilotnum)\n",
    "        else:\n",
    "            torch.save(model.state_dict(), 'model%d.pth'%Pilotnum)\n",
    "        best_ber = avg_eval_ber\n",
    "        print('Model saved!')\n",
    " \n",
    "    end_time = time.time()\n",
    "    print('Time cost:%ds'%(round(end_time-start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change hyper-parameters\n",
    "# transformer or other networks\n",
    "# add EMA\n",
    "# Ensemble\n",
    "\n",
    "print(\"BEST BER: %.4f\"%best_ber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(gpu_list.split(',')) > 1:\n",
    "    model = model.module\n",
    "    \n",
    "model.load_state_dict(torch.load('model%d.pth'%Pilotnum))\n",
    "    \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Pilotnum==32:\n",
    "    name = '../input/Y_1.csv'\n",
    "elif Pilotnum==8:\n",
    "    name = '../input/Y_2.csv'\n",
    "with open(name) as f:\n",
    "    Y = f.readlines()\n",
    "    \n",
    "for idx, line in enumerate(Y): \n",
    "    Y[idx] = list(map(float, line.split(',')))\n",
    "    \n",
    "Y = np.array(Y)\n",
    "if RESHAPE:\n",
    "    Y = Y.reshape(Y.shape[0],256,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = 100\n",
    "result = []\n",
    "save = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(int(len(Y)/test_batch)):\n",
    "        start = test_batch*i\n",
    "        end = min(test_batch*(i+1), len(Y))\n",
    "        input_Y = torch.from_numpy(Y[start:end].astype(np.float32)).cuda()\n",
    "        output = model(input_Y)\n",
    "        output = output.detach().cpu().numpy() \n",
    "        if MSE_or_BCE: # bce\n",
    "            save.append(sigmoid(output))\n",
    "        else:\n",
    "            save.append(output)\n",
    "        output = output > thre\n",
    "        result.append(output)\n",
    "\n",
    "result = np.concatenate(result, axis=0)\n",
    "save = np.concatenate(save, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Pilotnum==32:\n",
    "    np.save('X_pre_1_%.4f.npy'%best_ber, save)\n",
    "elif Pilotnum==8:\n",
    "    np.save('X_pre_2_%.4f.npy'%best_ber, save)\n",
    "else:\n",
    "    print('Check the Pilotnum param!!!')\n",
    "\n",
    "if Pilotnum==32:\n",
    "    result.tofile('X_pre_1.bin')\n",
    "elif Pilotnum==8:\n",
    "    result.tofile('X_pre_2.bin')\n",
    "else:\n",
    "    print('Check the Pilotnum param!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
